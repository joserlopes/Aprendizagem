{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, tree\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Reading the ARFF file\n",
    "data = loadarff('column_diagnosis.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['class'] = df['class'].str.decode('utf-8')\n",
    "df.head()\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score, f_pvalues = f_classif(X, y)\n",
    "\n",
    "data_tb = {'F-score': f_score, 'p-values': f_pvalues}\n",
    "tb = pd.DataFrame(data_tb)\n",
    "\n",
    "#Input variable w/ highest discriminative power: degree_spondylolisthesis\n",
    "#Input variable w/ lowest discriminative power: pelvic_radius\n",
    "\n",
    "sns.kdeplot(data=df, x='degree_spondylolisthesis', hue='class')\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(data=df, x='pelvic_radius', hue='class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree_spondylolisthesis input variable is the one that has the most discriminative power out of the 6 and pelvic_tilt is the one with less discriminative power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)\n",
    "depth_values = [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "df_data = []\n",
    "\n",
    "for depth_value in depth_values:\n",
    "    predictor = tree.DecisionTreeClassifier(max_depth=depth_value, random_state=0)\n",
    "    predictor.fit(X_train, y_train)\n",
    "    y_test_pred = predictor.predict(X_test)\n",
    "    y_train_pred = predictor.predict(X_train)\n",
    "    test_accuracy = round(metrics.accuracy_score(y_test, y_test_pred), 2) * 100\n",
    "    train_accuracy = round(metrics.accuracy_score(y_train, y_train_pred), 2) * 100\n",
    "    df_data.append({\"Max Depth\": depth_value, \"Test Accuracy (%)\": test_accuracy, \"Train Accuracy (%)\": train_accuracy})\n",
    "\n",
    "df = pd.DataFrame(df_data, columns=[\"Max Depth\", \"Test Accuracy (%)\", \"Train Accuracy (%)\"])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Max Depth', y=\"Test Accuracy (%)\", label=\"Test Accuracy (%)\", data=df, color='r', marker='o')\n",
    "sns.lineplot(x='Max Depth', y=\"Train Accuracy (%)\", label=\"Train Accuracy (%)\", data=df, color='g', marker='o')\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "- As we can see the train accuracy is substantially higher than the test accuracy, ending up at 100% with a depth limit of 8, this might mean that our decision tree model is overfitted for our specific parameters.\n",
    "- Although this is true, we can also see that as max depth grows, so does the accuracy of both the training set and the test set, meaning the generalization capacity across the multiple depth limit settings increases as the depth limit also increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "predictor = tree.DecisionTreeClassifier(min_samples_leaf=20, random_state=0)\n",
    "predictor.fit(X_train, y_train)\n",
    "\n",
    "figure = plt.figure(figsize=(12, 6))\n",
    "tree.plot_tree(predictor, feature_names=[\"pelvic_incidence\", \"pelvic_tilt\", \"lumbar_lordosis_angle\", \"sacral_slope\", \"pelvic_radius\", \"degree_spondylolisthesis\"], class_names=[\"Hernia\", \"Spondylolisthesis\", \"Normal\"], impurity=False)\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
